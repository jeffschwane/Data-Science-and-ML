{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# classifier we will use\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# model selection bits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Spam with Decision Trees\n",
    "\n",
    "In this assignment you will detect spam with decision trees. It's always important to investigate the data that you are using for any project. Since data is our gold mine, it's our oil that powers our models we need to have good quality data. Machine learning follows the \"garbage in, garbage out\" principle, if we feed in bad data for training, we will get a model that produces bad results.  For these reasons we want to answer the following questions.\n",
    "\n",
    "## 0.  Learn about the data\n",
    "\n",
    "1. Where did this data come from? George Forman at HP (filed work and personal emails), spam e-mails came from their postmaster and individuals who had filed spam\n",
    "2. Who made it? HP company in 1999 (Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt)\n",
    "3. How were the features selected? Not sure, but seems to be frequent words and sequences that came up in the spam emails\n",
    "4. Can you trust it? Yes, though this is specific to the individual (George). They noted that more data would be needed to make it more general.\n",
    "\n",
    "Go ahead and scan through the spambase_features.txt file and the spambase.txt file.  These two files provide information about the dataset, how it was curated and where it came from. Then try to answer the above questions.\n",
    "\n",
    "\n",
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we are going to hardcode the column names, because this just makes it a little easier to use pandas.\n",
    "\n",
    "names = ['word_freq_make:        ',\n",
    "'word_freq_address:     ',\n",
    "'word_freq_all:         ',\n",
    "'word_freq_3d:          ',\n",
    "'word_freq_our:         ',\n",
    "'word_freq_over:        ',\n",
    "'word_freq_remove:      ',\n",
    "'word_freq_internet:    ',\n",
    "'word_freq_order:       ',\n",
    "'word_freq_mail:        ',\n",
    "'word_freq_receive:     ',\n",
    "'word_freq_will:        ',\n",
    "'word_freq_people:      ',\n",
    "'word_freq_report:      ',\n",
    "'word_freq_addresses:   ',\n",
    "'word_freq_free:        ',\n",
    "'word_freq_business:    ',\n",
    "'word_freq_email:       ',\n",
    "'word_freq_you:         ',\n",
    "'word_freq_credit:      ',\n",
    "'word_freq_your:        ',\n",
    "'word_freq_font:        ',\n",
    "'word_freq_000:         ',\n",
    "'word_freq_money:       ',\n",
    "'word_freq_hp:          ',\n",
    "'word_freq_hpl:         ',\n",
    "'word_freq_george:      ',\n",
    "'word_freq_650:         ',\n",
    "'word_freq_lab:         ',\n",
    "'word_freq_labs:        ',\n",
    "'word_freq_telnet:      ',\n",
    "'word_freq_857:         ',\n",
    "'word_freq_data:        ',\n",
    "'word_freq_415:         ',\n",
    "'word_freq_85:          ',\n",
    "'word_freq_technology:  ',\n",
    "'word_freq_1999:        ',\n",
    "'word_freq_parts:       ',\n",
    "'word_freq_pm:          ',\n",
    "'word_freq_direct:      ',\n",
    "'word_freq_cs:          ',\n",
    "'word_freq_meeting:     ',\n",
    "'word_freq_original:    ',\n",
    "'word_freq_project:     ',\n",
    "'word_freq_re:          ',\n",
    "'word_freq_edu:         ',\n",
    "'word_freq_table:       ',\n",
    "'word_freq_conference:  ',\n",
    "'char_freq_;:           ',\n",
    "'char_freq_(:           ',\n",
    "'char_freq_[:           ',\n",
    "'char_freq_!:           ',\n",
    "'char_freq_$:           ',\n",
    "'char_freq_#:           ',\n",
    "'capital_run_length_average',\n",
    "'capital_run_length_longest',\n",
    "'capital_run_length_total: ',\n",
    "'label']\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the dataset here \n",
    "\n",
    "data = pd.read_csv('spambase/spambase.csv', names = names)\n",
    "X = data.drop('label', axis = 1)\n",
    "y = data.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data if needed\n",
    "\n",
    "1. Are there any empty values?\n",
    "2. Do you need to transform the data?\n",
    "3. What is the distribution of the positive and negative classes?\n",
    "4. Split the data into training and testing sets\n",
    "\n",
    "Let me give a few hints.  When it comes to scaling the data, we normally just _should_, but in this case we are going to be working with decision trees and I think we learned that they have an interesting property!  \n",
    "\n",
    "We want to look at the distribution of positive (spam) and negative (ham) classes.  So basically we need to look at the count of the labels.  You can use the function `.value_counts()` on `y`.  Note that the function `value_counts` is specific to the Series class, it doesn't work on Dataframes.  Now it's not just enough to look at the raw numbers, I suggest you calculate statistics like \"what percentage of my data is ham? What percentage is spam?  This may help you decide if you should use the `stratify` keyword when splitting your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2788\n",
       "1    1813\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6059552271245382"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2788 / (2788+1813)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39404477287546186"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1813 / (2788+1813)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split your data with 70% for training, this is somewhat random, but this is how I will do it in the \n",
    "## solution video so you will have similar results. Feel free to change this value and experiment if you like.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a Decision Tree Classifier\n",
    "\n",
    "1. What metric should we use? The f1-score or accuracy?\n",
    "\n",
    "Let's start with a default model, we won't specify any settings on the decision tree model for the first training. The following will be a 3-step process\n",
    " * training\n",
    " * getting predictions\n",
    " * evaluating our predictions\n",
    " \n",
    "The question does arise, what should we check our predictions on? The obvious answer is that we should check the predictions on our testing set. That's the set of data that simulates our future unseen data. However in our quest to figure out if we are overfitting or not, it could be very useful to look at the performance of the training set.  Remember when we overfit our polynomials and they touched every point? But then we added data the performance would drop. Similarly if the perfomance of the training data is near perfect, but the testing data is much worse, that _gap_ indicates overfitting. So we will check both training and testing performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the model\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get predictions from the model on the training data and the testing data\n",
    "test_predictions = clf.predict(X_test)\n",
    "train_predictions = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8780019212295869\n"
     ]
    }
   ],
   "source": [
    "## evaluate the predictions\n",
    "## Note that the order of the arguments is **very** important for f1-score\n",
    "\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992283950617284\n"
     ]
    }
   ],
   "source": [
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "print(train_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9080376538740044\n"
     ]
    }
   ],
   "source": [
    "test_acc = accuracy_score(y_test, test_predictions)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993788819875776\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy_score(y_train, train_predictions)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Did we overfit? Either way, let's try out some of the decision tree parameters\n",
    "\n",
    "Go ahead and try out some different tree parameters. \n",
    "\n",
    "* `max_depth`\n",
    "* `min_samples_split`\n",
    "* `min_samples_leaf`\n",
    "\n",
    "All three of these parameters will control the complexity of the tree.  Before you try them out, let's take a quick quiz:\n",
    "\n",
    "* increasing `max_depth` will : **Increase** or **Decrease** overfitting? Increase!\n",
    "* increasing `min_samples_split` will: **Increase** or **Decrease** overfitting? Decrease!\n",
    "* increasing `min_samples_leaf` will: **Increase** or **Decrease** overfitting? Decrease!\n",
    "\n",
    "It's very important to know the answer to these questions - because other wise you can't tune the parameters correctly. If you aren't sure go back and check the quiz on this very topic.\n",
    "\n",
    "Go ahead and try at least 3 values for each parameter. Then if you try 3 values for each combination, you actually would try 9 total parameters. You can see where this is going -- `for` loops! At this point I encourage you to just try whatever method you want, you can ad-hoc try different values or you can get robust with for-loops. Whatever you are inspired to do. The main point is to try out some values and see what you find.  What helps improve our testing performance the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=2, min_samples_leaf=1\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=2, min_samples_leaf=1\n",
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=2, min_samples_leaf=3\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=2, min_samples_leaf=3\n",
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=2, min_samples_leaf=5\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=2, min_samples_leaf=5\n",
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=3, min_samples_leaf=1\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=3, min_samples_leaf=1\n",
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=3, min_samples_leaf=3\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=3, min_samples_leaf=3\n",
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=3, min_samples_leaf=5\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=3, min_samples_leaf=5\n",
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=4, min_samples_leaf=1\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=4, min_samples_leaf=1\n",
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=4, min_samples_leaf=3\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=4, min_samples_leaf=3\n",
      "F1 test = 0.6706161137440758 for max_depth=1, min_samples_split=4, min_samples_leaf=5\n",
      "F1 train = 0.6803239637922821 for max_depth=1, min_samples_split=4, min_samples_leaf=5\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=2, min_samples_leaf=1\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=2, min_samples_leaf=1\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=2, min_samples_leaf=3\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=2, min_samples_leaf=3\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=2, min_samples_leaf=5\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=2, min_samples_leaf=5\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=3, min_samples_leaf=1\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=3, min_samples_leaf=1\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=3, min_samples_leaf=3\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=3, min_samples_leaf=3\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=3, min_samples_leaf=5\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=3, min_samples_leaf=5\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=4, min_samples_leaf=1\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=4, min_samples_leaf=1\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=4, min_samples_leaf=3\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=4, min_samples_leaf=3\n",
      "F1 test = 0.7938931297709925 for max_depth=2, min_samples_split=4, min_samples_leaf=5\n",
      "F1 train = 0.8101487314085739 for max_depth=2, min_samples_split=4, min_samples_leaf=5\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=2, min_samples_leaf=1\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=2, min_samples_leaf=1\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=2, min_samples_leaf=3\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=2, min_samples_leaf=3\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=2, min_samples_leaf=5\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=2, min_samples_leaf=5\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=3, min_samples_leaf=1\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=3, min_samples_leaf=1\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=3, min_samples_leaf=3\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=3, min_samples_leaf=3\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=3, min_samples_leaf=5\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=3, min_samples_leaf=5\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=4, min_samples_leaf=1\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=4, min_samples_leaf=1\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=4, min_samples_leaf=3\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=4, min_samples_leaf=3\n",
      "F1 test = 0.8316086547507054 for max_depth=3, min_samples_split=4, min_samples_leaf=5\n",
      "F1 train = 0.8556311413454272 for max_depth=3, min_samples_split=4, min_samples_leaf=5\n"
     ]
    }
   ],
   "source": [
    "for max_d in [1,2,3]:\n",
    "    for min_ss in [2,3,4]:\n",
    "        for min_sl in [1,3,5]:\n",
    "            clf = DecisionTreeClassifier(max_depth=max_d,\n",
    "                                        min_samples_split=min_ss,\n",
    "                                        min_samples_leaf=min_sl)\n",
    "            clf.fit(X_train,y_train)\n",
    "            test_predictions = clf.predict(X_test)\n",
    "            train_predictions = clf.predict(X_train)\n",
    "            test_f1 = f1_score(y_test, test_predictions)\n",
    "            print(f'F1 test = {test_f1} for max_depth={max_d}, min_samples_split={min_ss}, min_samples_leaf={min_sl}')\n",
    "            train_f1 = f1_score(y_train, train_predictions)\n",
    "            print(f'F1 train = {train_f1} for max_depth={max_d}, min_samples_split={min_ss}, min_samples_leaf={min_sl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok, now let's do it systematically\n",
    "\n",
    "Let's do it with some for loops. This will lead us to having more data than we can \"look\" at, so naturally we will plot it.\n",
    "I've started the for loop for you, you need to fill in the inner part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8101487314085739, 0.8556311413454272, 0.8849918433931484, 0.9057824504650221, 0.9203396684189243, 0.9294210943695479, 0.944731610337972, 0.9539188656951555, 0.9593046226787831, 0.9697920753236563, 0.972276454509957, 0.9776558212465699, 0.9808219178082191, 0.9831702544031312, 0.9851446442533229, 0.98671875, 0.9871244635193133, 0.989522700814901, 0.9922299922299922, 0.9930124223602486, 0.9930124223602486, 0.9930124223602486, 0.9938223938223938, 0.9965183752417794, 0.9976816074188563, 0.998842145889618, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284, 0.9992283950617284]\n",
      " \n",
      "[0.7938931297709925, 0.8316086547507054, 0.8521560574948664, 0.8661899897854954, 0.8725790010193679, 0.875751503006012, 0.878391959798995, 0.8787276341948311, 0.889110889110889, 0.8833992094861661, 0.8803921568627451, 0.8825831702544031, 0.8736532810969636, 0.8740157480314961, 0.87890625, 0.8741463414634145, 0.8713450292397661, 0.8753623188405797, 0.8718929254302104, 0.8816169393647738, 0.875239923224568, 0.8812260536398466, 0.8717948717948718, 0.86558627264061, 0.8697318007662835, 0.8802281368821293, 0.8774928774928775, 0.8708765315739868, 0.8703878902554399, 0.8796208530805687, 0.8742857142857143, 0.8771266540642721, 0.8728652751423149, 0.875829383886256, 0.8736942070275403, 0.876425855513308, 0.8831417624521073, 0.8713060057197332, 0.8776290630975144, 0.880611270296084, 0.8772597526165558, 0.8698955365622032, 0.8698955365622032, 0.8768939393939394, 0.8644549763033176, 0.8731060606060607, 0.8732125834127741, 0.8717948717948718]\n"
     ]
    }
   ],
   "source": [
    "train_results = []\n",
    "test_results = []\n",
    "for i in range(2,50): # feel free to change these, I just threw out a reasonable option here.\n",
    "    \n",
    "    dtc = DecisionTreeClassifier(max_depth=i)  #select a parameter to check\n",
    "    dtc.fit(X_train,y_train)         # train the model\n",
    "    test_predictions = dtc.predict(X_test)\n",
    "    train_predictions = dtc.predict(X_train)    # get predictions for both training and test\n",
    "    test_f1 = f1_score(y_test, test_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    train_results.append(train_f1)\n",
    "    test_results.append(test_f1) # evaluate them and append them into the our lists.\n",
    "\n",
    "print(train_results)\n",
    "print ( \" \")\n",
    "print (test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's a lot of numbers!\n",
    "\n",
    "What do all those numbers tell us? Well we can pick out the best values using something like `np.max` and then we can relate it to the best parameter with the argument that correlates to that value (so depth 2 gave us .85 score etc).  But I think we'll find more interesting to plot these points.  I've provided the code for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c6e90aaa90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,6));\n",
    "ax.plot(train_results, color = 'r', label = 'train')\n",
    "ax.plot(test_results, color = 'b', label = 'test')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This graph is called a validation curve\n",
    "\n",
    "What we have done is plotted the performance of the training and testing data against a parameter that was varied. How do we read this graph?\n",
    "What information can you glean?\n",
    "When does our model start to overfit?  \n",
    "Based on what you see here, what do you think the best choice for the parameter you were checking is?  That is, looking at the graph, what value would you choose for a spam detection model that you were going to deploy? Don't forget the purpose of the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on looking at the graph, the test data scores start to flatten out around a max depth of ~7 (index 5), whereas the train data scores continue to increase. This shows that any depth larger than ~7 will begin to overfit the model, so I would use that parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally... we ... made a mistake!\n",
    "Do you see what the giant mistake we did? Go ahead and let us know below.\n",
    "If you don't see the mistake... don't worry I'll explain in the next unit!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis isn't the max_depth, it's the index position of the list value from 2 to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
